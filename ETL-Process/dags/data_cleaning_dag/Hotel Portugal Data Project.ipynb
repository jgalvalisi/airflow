{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20f3f88",
   "metadata": {},
   "source": [
    "## Hotel Portugal Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b38520",
   "metadata": {},
   "source": [
    "### This Jupyter Notebook contains the following points:\n",
    "\n",
    "* 1 - Import libraries\n",
    "* 2 - Cleaning data\n",
    "* 3 - Airflow tasks\n",
    "* 4 - Define dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9d0a6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc48bca",
   "metadata": {},
   "source": [
    "### 1- Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa0a64ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "A non-annotated attribute was detected: `dag_id = <class 'str'>`. All model fields require a type annotation; if `dag_id` is not meant to be a field, you may be able to resolve this error by annotating it as a `ClassVar` or updating `model_config['ignored_types']`.\n\nFor further information visit https://errors.pydantic.dev/2.0/u/model-field-missing-annotation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v4/vhqj6hzj0d74y_htnnl_mb7c0000gn/T/ipykernel_31972/2074995956.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDAG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPythonOperator\u001b[0m \u001b[0;31m# Will be used in our tasks to run any Python code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdag_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/airflow/operators/python.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseoperator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseOperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskipmixin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSkipMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaskinstance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_CURRENT_CONTEXT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_copy_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_merge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/airflow/models/skipmixin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAirflowException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRemovedInAirflow3Warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaskinstance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTaskInstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdag_run\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDagRunPydantic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_mixin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoggingMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/airflow/serialization/pydantic/dag_run.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mBaseModelPydantic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetEventPydantic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/airflow/serialization/pydantic/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTaskOutletDatasetReferencePydantic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseModelPydantic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0mSerializable\u001b[0m \u001b[0mrepresentation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydantic/_internal/_model_construction.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mconfig_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfigWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mnamespace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             private_attributes = inspect_namespace(\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignored_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_field_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydantic/_internal/_model_construction.py\u001b[0m in \u001b[0;36minspect_namespace\u001b[0;34m(namespace, ignored_types, base_class_vars, base_class_fields)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 )\n\u001b[1;32m    327\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 raise PydanticUserError(\n\u001b[0m\u001b[1;32m    329\u001b[0m                     \u001b[0;34mf\"A non-annotated attribute was detected: `{var_name} = {value!r}`. All model fields require a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                     \u001b[0;34mf\"type annotation; if `{var_name}` is not meant to be a field, you may be able to resolve this \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPydanticUserError\u001b[0m: A non-annotated attribute was detected: `dag_id = <class 'str'>`. All model fields require a type annotation; if `dag_id` is not meant to be a field, you may be able to resolve this error by annotating it as a `ClassVar` or updating `model_config['ignored_types']`.\n\nFor further information visit https://errors.pydantic.dev/2.0/u/model-field-missing-annotation"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta # To calculate duration\n",
    "import airflow # Required to run DAG\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator # Will be used in our tasks to run any Python code\n",
    "\n",
    "dag_patch = os.getcwd()\n",
    "\n",
    "\n",
    "def data_cleaning():\n",
    "    dag_folder = os.path.dirname(__file__)\n",
    "    data_path = os.path.join(dag_folder, 'raw_data/hotel_booking_portugal_data.csv')\n",
    "    hotel_data = pd.read_csv(data_path)\n",
    "    hotel_data.head() # First row\n",
    "    hotel_data.info() # Printing info of our dataframe\n",
    "    hotel_data.describe() # Description of our dataframe\n",
    "\n",
    "    hotel_data.isnull().sum() # Checking null columns\n",
    "\n",
    "    nan_replacements = {'children': 0,\n",
    "                        'country': 'Unknown',\n",
    "                        'agent': 'Organic Booking',\n",
    "                        'company': 'Personal Booking'\n",
    "                        }\n",
    "    \n",
    "    cleaned_data = hotel_data.fillna(nan_replacements)\n",
    "\n",
    "    cleaned_data.info()\n",
    "\n",
    "    # Storing cleaned data\n",
    "\n",
    "    #cleaned_data.to_csv('/processed_data/hotel_booking_portugal_data.csv', index = False)\n",
    "    processed_data_path = os.path.join(dag_folder, 'processed_data/hotel_booking_portugal_data.csv')\n",
    "    cleaned_data.to_csv(processed_data_path, index=False)\n",
    "\n",
    "def cleaned_data_message():\n",
    "    print(\"Data successfully cleaned\")\n",
    "\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': airflow.utils.dates.days_ago(7) # Date when the DAG should start running\n",
    "}\n",
    "\n",
    "data_cleaning_dag = DAG(\n",
    "    'data_cleaning_dag',\n",
    "    default_args = default_args,\n",
    "    schedule_interval = timedelta (days=30),\n",
    "    #catchup_by_default = False\n",
    ")\n",
    "\n",
    "\n",
    "# Airflow Tasks\n",
    "\n",
    "t1_clean_data = PythonOperator (\n",
    "    task_id = 'data_cleaning',\n",
    "    python_callable = data_cleaning,\n",
    "    dag = data_cleaning_dag\n",
    ")\n",
    "\n",
    "t2_message = PythonOperator(\n",
    "    task_id = 'cleaned_data_message',\n",
    "    python_callable = cleaned_data_message,\n",
    "    dag = data_cleaning_dag\n",
    ")\n",
    "\n",
    "t1_clean_data >> t2_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f432c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta # To calculate duration\n",
    "import airflow # Required to run DAG\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#from airflow import DAG\n",
    "#from airflow.operators.python import PythonOperator # Will be used in our tasks to run any Python code\n",
    "\n",
    "dag_patch = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a955d0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355edb0b",
   "metadata": {},
   "source": [
    "### 2- Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1397fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning():\n",
    "    dag_folder = os.path.dirname(__file__)\n",
    "    data_path = os.path.join(dag_folder, 'raw_data/hotel_booking_portugal_data.csv')\n",
    "    hotel_data = pd.read_csv(data_path)\n",
    "    hotel_data.head() # First row\n",
    "    hotel_data.info() # Printing info of our dataframe\n",
    "    hotel_data.describe() # Description of our dataframe\n",
    "\n",
    "    hotel_data.isnull().sum() # Checking null columns\n",
    "\n",
    "    nan_replacements = {'children': 0,\n",
    "                        'country': 'Unknown',\n",
    "                        'agent': 'Organic Booking',\n",
    "                        'company': 'Personal Booking'\n",
    "                        }\n",
    "    \n",
    "    cleaned_data = hotel_data.fillna(nan_replacements)\n",
    "\n",
    "    cleaned_data.info()\n",
    "\n",
    "    # Storing cleaned data\n",
    "\n",
    "    #cleaned_data.to_csv('/processed_data/hotel_booking_portugal_data.csv', index = False)\n",
    "    processed_data_path = os.path.join(dag_folder, 'processed_data/hotel_booking_portugal_data.csv')\n",
    "    cleaned_data.to_csv(processed_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9242cb13",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v4/vhqj6hzj0d74y_htnnl_mb7c0000gn/T/ipykernel_31972/836914603.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdag_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "    dag_folder = os.path.dirname(__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12068dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "    data_path = os.path.join(dag_folder, 'raw_data/hotel_booking_portugal_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "    hotel_data = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "    hotel_data.head() # First row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    hotel_data.info() # Printing info of our dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c4f0a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hotel_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v4/vhqj6hzj0d74y_htnnl_mb7c0000gn/T/ipykernel_31972/2470403434.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcleaned_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhotel_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnan_replacements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hotel_data' is not defined"
     ]
    }
   ],
   "source": [
    "    cleaned_data = hotel_data.fillna(nan_replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32825f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v4/vhqj6hzj0d74y_htnnl_mb7c0000gn/T/ipykernel_31972/773499599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcleaned_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Check results\n",
    "\n",
    "cleaned_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b004853",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef559252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing cleaned data\n",
    "\n",
    "#cleaned_data.to_csv('/processed_data/hotel_booking_portugal_data.csv', index = False)\n",
    "processed_data_path = os.pa---th.join(dag_folder, 'processed_data/hotel_booking_portugal_data.csv')\n",
    "cleaned_data.to_csv(processed_data_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae38c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_data_message():\n",
    "    print(\"Data successfully cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': airflow.utils.dates.days_ago(7) # Date when the DAG should start running\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f505a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning_dag = DAG(\n",
    "    'data_cleaning_dag',\n",
    "    default_args = default_args,\n",
    "    schedule_interval = timedelta (days=30),\n",
    "    #catchup_by_default = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf4320d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024500bb",
   "metadata": {},
   "source": [
    "### 3- Airflow Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_clean_data = PythonOperator (\n",
    "    task_id = 'data_cleaning',\n",
    "    python_callable = data_cleaning,\n",
    "    dag = data_cleaning_dag\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ffc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3733a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_message = PythonOperator(\n",
    "    task_id = 'cleaned_data_message',\n",
    "    python_callable = cleaned_data_message,\n",
    "    dag = data_cleaning_dag\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec871fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138299f",
   "metadata": {},
   "source": [
    "### 4- Define dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393df5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data >> message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39f45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb8e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83eb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab19ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
